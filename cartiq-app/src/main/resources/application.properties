# ============================================
# CONFLUENT CLOUD CONFIGURATION
# ============================================
# Get these from your Confluent Cloud console
# Use the trial code: CONFLUENTDEV1

spring.kafka.bootstrap-servers=${CONFLUENT_BOOTSTRAP_SERVERS:localhost:9092}

# Confluent Cloud Authentication
confluent.api.key=${CONFLUENT_API_KEY:}
confluent.api.secret=${CONFLUENT_API_SECRET:}

# Confluent Schema Registry Configuration
# Get these from Confluent Cloud > Schema Registry > API credentials
confluent.schema.registry.url=${CONFLUENT_SCHEMA_REGISTRY_URL:}
confluent.schema.registry.api.key=${CONFLUENT_SR_API_KEY:}
confluent.schema.registry.api.secret=${CONFLUENT_SR_API_SECRET:}

# Consumer config
spring.kafka.consumer.group-id=cartiq-group
spring.kafka.consumer.auto-offset-reset=earliest

# ============================================
# GOOGLE CLOUD VERTEX AI CONFIGURATION
# ============================================
# Get these from your Google Cloud Console

vertex.ai.project-id=${GCP_PROJECT_ID:}
vertex.ai.location=${GCP_LOCATION:us-central1}
vertex.ai.endpoint=${VERTEX_AI_ENDPOINT:}

# For local development, you can use Application Default Credentials
# Run: gcloud auth application-default login

# ============================================
# APPLICATION CONFIGURATION
# ============================================
spring.profiles.active=${SPRING_PROFILES_ACTIVE:dev}
server.port=8082

# CORS Configuration - set CORS_ALLOWED_ORIGINS for production
cors.allowed-origins=${CORS_ALLOWED_ORIGINS:http://localhost:3000,http://localhost:5173}

# ============================================
# DATABASE CONFIGURATION (Cloud SQL PostgreSQL)
# ============================================
# For local development: use public IP connection
# For Cloud Run: override SPRING_DATASOURCE_URL with socket factory URL
spring.datasource.url=${SPRING_DATASOURCE_URL}
spring.datasource.username=${env.SPRING_DATASOURCE_USERNAME}
spring.datasource.password=${SPRING_DATASOURCE_PASSWORD}
spring.datasource.driver-class-name=org.postgresql.Driver

# JPA/Hibernate
spring.jpa.database-platform=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=false

# Connection pool settings
spring.datasource.hikari.maximum-pool-size=20
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.connection-timeout=30000
spring.datasource.hikari.idle-timeout=600000
spring.datasource.hikari.max-lifetime=1800000
spring.datasource.hikari.leak-detection-threshold=60000

# ============================================
# JACKSON (JSON) CONFIGURATION
# ============================================
spring.jackson.mapper.accept-case-insensitive-enums=true

# ============================================
# LOGGING
# ============================================
logging.level.com.cartiq=DEBUG
logging.level.org.apache.kafka=WARN
# Suppress harmless Hibernate schema update warnings about non-existent constraints
logging.level.org.hibernate.orm.jdbc.warn=ERROR

# ============================================
# JWT CONFIGURATION
# ============================================
# SECURITY WARNING: Set JWT_SECRET environment variable in production!
# The default value is ONLY for local development.
jwt.secret=${JWT_SECRET}
jwt.expiration=86400000

# ============================================
# ACTUATOR
# ============================================
management.endpoints.web.exposure.include=health,info
management.endpoint.health.show-details=when_authorized

# ============================================
# VERTEX AI VECTOR SEARCH (RAG)
# ============================================
# Vector Search index endpoint
cartiq.rag.vectorsearch.index-endpoint=${VECTOR_SEARCH_INDEX_ENDPOINT:}
cartiq.rag.vectorsearch.deployed-index-id=${VECTOR_SEARCH_DEPLOYED_INDEX_ID}
cartiq.rag.vectorsearch.api-endpoint=${VECTOR_SEARCH_API_ENDPOINT}

# ============================================
# REDIS CACHE (EMBEDDING CACHE)
# ============================================
spring.data.redis.host=${REDIS_HOST}
spring.data.redis.port=${REDIS_PORT}
spring.data.redis.password=${REDIS_PASSWORD}

# ============================================
# RAG CONFIGURATION
# ============================================
cartiq.rag.enabled=${RAG_ENABLED:true}

# Embedding settings
cartiq.rag.embedding.model=${RAG_EMBEDDING_MODEL:text-embedding-004}
cartiq.rag.embedding.dimensions=${RAG_EMBEDDING_DIMENSIONS:768}

# Retrieval settings
cartiq.rag.retrieval.initial-candidates=${RAG_RETRIEVAL_TOP_K:50}
cartiq.rag.retrieval.final-results=${RAG_RETRIEVAL_FINAL_RESULTS:10}
cartiq.rag.retrieval.similarity-threshold=${RAG_RETRIEVAL_SIMILARITY_THRESHOLD:0.7}

# Re-ranking settings
cartiq.rag.reranking.enabled=${RAG_RERANKING_ENABLED:true}
cartiq.rag.reranking.model=${RAG_RERANKING_MODEL:semantic-ranker-512@latest}

# Cache TTLs
cartiq.rag.cache.product-embedding-ttl=${RAG_CACHE_PRODUCT_TTL_HOURS:24}h
cartiq.rag.cache.query-embedding-ttl=${RAG_CACHE_QUERY_TTL_HOURS:1}h

# Indexing settings
cartiq.rag.indexing.batch-size=100
cartiq.rag.indexing.on-startup=true

# ============================================
# ADMIN INITIALIZATION
# ============================================
# Set these environment variables to create an admin user on startup.
# The admin is only created if:
#   1. ADMIN_EMAIL is set (not empty)
#   2. ADMIN_PASSWORD is set (min 8 characters)
#   3. No user with that email already exists
#
# In GCP Cloud Run, use Secret Manager for ADMIN_PASSWORD:
#   gcloud run deploy cartiq --set-secrets=ADMIN_PASSWORD=admin-password:latest
#
app.admin.email=${ADMIN_EMAIL}
app.admin.password=${ADMIN_PASSWORD}
app.admin.first-name=${ADMIN_FIRST_NAME}
app.admin.last-name=${ADMIN_LAST_NAME}
