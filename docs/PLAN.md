# CartIQ - 19-Day Implementation Plan

**Hackathon:** AI Partner Catalyst: Accelerate Innovation (Confluent Challenge)
**Deadline:** December 31, 2025 (2:00 PM PT)
**Start Date:** December 12, 2025
**Days Remaining:** 19 days
**Daily Commitment:** 10-12 hours (avg 11h/day = 209 hours total)

---

## Progress Summary

### Completed Modules
- [x] cartiq-common (Shared utilities)
- [x] cartiq-user (Authentication, profiles, JWT)
- [x] cartiq-product (Product catalog, categories, search)
- [x] cartiq-order (Cart, orders, checkout)
- [x] cartiq-app (Main application assembly)
- [x] cartiq-kafka (Confluent Cloud setup, topics created, event publishing working)

### In Progress
- [ ] cartiq-rag (Production RAG module) **â† NEW**
- [ ] cartiq-ai (Gemini integration pending)

### Remaining Work
- [ ] GCP RAG Infrastructure (Vector Search, Redis)
- [ ] Production RAG Pipeline (Embeddings, Indexing, Re-ranking)
- [ ] Flink Streaming (User context aggregation) **â† Critical Path**
- [ ] Vertex AI / Gemini integration
- [ ] Data Seeder (Demo data + live simulation)
- [ ] Frontend (React + Firebase Hosting)
- [ ] Demo Video + Submission

---

## What's New: Production-Grade RAG

This plan includes a **production-grade RAG architecture** for product recommendations:

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Vector Store** | Vertex AI Vector Search | Scalable semantic search |
| **Embedding Cache** | Cloud Memorystore (Redis) | Reduce API latency |
| **Incremental Indexing** | Spring Events + Async | Real-time index updates |
| **Re-ranking** | Vertex AI Ranking API | Two-stage retrieval precision |

See `docs/updateArchitecture.md` for full technical details.

---

## Judging Criteria & Strategy

| Criteria | Weight | Strategy |
|----------|--------|----------|
| **Technological Implementation** | 25% | Kafka â†’ Flink â†’ RAG â†’ Gemini pipeline |
| **Design/UX** | 25% | Clean React UI + AI chat widget + Firebase Hosting |
| **Potential Impact** | 25% | "Democratizing personalization for small businesses" |
| **Quality of Idea** | 25% | "Cold Start Killer" + Production-grade RAG |

---

## 19-Day Timeline Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         19-DAY EXECUTION PLAN                               â”‚
â”‚                    Target: 11h/day avg (209h total)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  PHASE 1: GCP INFRASTRUCTURE (Days 1-2)                      22h           â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚  Day 1:  Vertex AI Vector Search + Redis setup                11h          â”‚
â”‚  Day 2:  Gemini integration + basic chat endpoint             11h          â”‚
â”‚                                                                             â”‚
â”‚  PHASE 2: RAG PIPELINE (Days 3-6)                            44h           â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚  Day 3:  cartiq-rag module + EmbeddingService + cache         11h          â”‚
â”‚  Day 4:  VectorSearchService + startup indexer                11h          â”‚
â”‚  Day 5:  Incremental indexer + product CRUD events            11h          â”‚
â”‚  Day 6:  ReRanker + ProductRetriever + AI integration         11h          â”‚
â”‚                                                                             â”‚
â”‚  PHASE 3: FLINK STREAMING (Days 7-8)                         22h           â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚  Day 7:  Flink SQL tables + user behavior aggregation         11h          â”‚
â”‚  Day 8:  UserContext cache + Kafka consumer + testing         11h          â”‚
â”‚                                                                             â”‚
â”‚  PHASE 4: FRONTEND (Days 9-12)                               44h           â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚  Day 9:  React setup + routing + product listing              11h          â”‚
â”‚  Day 10: Product detail + cart functionality                  11h          â”‚
â”‚  Day 11: Checkout + order flow + auth                         11h          â”‚
â”‚  Day 12: AI chat widget + event tracking + home recs          11h          â”‚
â”‚                                                                             â”‚
â”‚  PHASE 5: INTEGRATION & POLISH (Days 13-15)                  33h           â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚  Day 13: End-to-end testing + cold start optimization         11h          â”‚
â”‚  Day 14: Data seeder + demo data preparation                  11h          â”‚
â”‚  Day 15: Deployment (Cloud Run + Firebase) + bug fixes        11h          â”‚
â”‚                                                                             â”‚
â”‚  PHASE 6: DEMO & SUBMIT (Days 16-19)                         44h           â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚  Day 16: Production smoke testing + final bug fixes           11h          â”‚
â”‚  Day 17: Demo video recording                                 11h          â”‚
â”‚  Day 18: Demo video editing + upload                          11h          â”‚
â”‚  Day 19: Final testing + Devpost submission                   11h          â”‚
â”‚                                                                             â”‚
â”‚  TOTAL: 209 hours                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Detailed Daily Plan

### Phase 1: GCP Infrastructure (Days 1-2)

#### Day 1 - GCP RAG Infrastructure (11h)

**Goals:**
- Set up Vertex AI Vector Search index
- Set up Cloud Memorystore Redis
- Configure networking and IAM

**Tasks:**
```
â–¡ Vertex AI Vector Search:
  â–¡ Enable Vertex AI API in GCP Console
  â–¡ Create Vector Search index:
    - Display name: cartiq-products-index
    - Dimensions: 768 (for text-embedding-004)
    - Distance measure: COSINE_DISTANCE
    - Update method: STREAM_UPDATE
  â–¡ Create index endpoint
  â–¡ Deploy index to endpoint
  â–¡ Note: Index creation takes ~30-60 minutes

â–¡ Cloud Memorystore Redis:
  â–¡ Create Redis instance (1GB Basic tier)
  â–¡ Note VPC network and IP address
  â–¡ Configure firewall rules if needed

â–¡ IAM & Service Accounts:
  â–¡ Create service account for RAG
  â–¡ Grant roles:
    - Vertex AI User
    - Vertex AI Feature Store User
    - Redis Client (if using IAM auth)
  â–¡ Download credentials JSON

â–¡ Test connectivity:
  â–¡ Verify Vector Search endpoint accessible
  â–¡ Verify Redis connection from local
```

**Deliverables:**
- Vector Search index deployed and ready
- Redis instance running
- Service account configured

---

#### Day 2 - Gemini Integration (11h)

**Goals:**
- Complete Vertex AI Gemini setup
- Implement basic chat endpoint
- Test shopping assistant responses

**Tasks:**
```
â–¡ Vertex AI Gemini Setup:
  â–¡ Verify Vertex AI API enabled
  â–¡ Create VertexAIConfig.java in cartiq-ai module
  â–¡ Configure application.properties:
    - GCP_PROJECT_ID
    - GCP_LOCATION (us-central1)
    - GOOGLE_APPLICATION_CREDENTIALS

â–¡ Implement GeminiService.java:
  â–¡ Initialize GenerativeModel client
  â–¡ Create generateContent() method
  â–¡ Add system prompt for shopping assistant persona
  â–¡ Handle streaming responses (optional)

â–¡ Implement Chat Endpoint:
  â–¡ Create ChatController.java (/api/chat/**)
  â–¡ Create ChatRequest DTO (userId, message)
  â–¡ Create ChatResponse DTO (response, contextUsed, productIds)
  â–¡ Wire up controller â†’ service

â–¡ Test scenarios:
  â–¡ "Recommend me a laptop under $1000"
  â–¡ "What's the best phone for photography?"
  â–¡ "Compare iPhone 15 and Samsung S24"
  â–¡ Verify responses are helpful and on-topic
```

**Deliverables:**
- Working /api/chat endpoint
- Gemini responding as shopping assistant
- Basic conversation flow tested

---

### Phase 2: RAG Pipeline (Days 3-6)

#### Day 3 - RAG Module: Embeddings + Cache (11h)

**Goals:**
- Create cartiq-rag module structure
- Implement embedding service with Redis caching
- Test embedding generation

**Tasks:**
```
â–¡ Create cartiq-rag module:
  â–¡ Create directory structure:
    cartiq-rag/
    â”œâ”€â”€ pom.xml
    â””â”€â”€ src/main/java/com/cartiq/rag/
        â”œâ”€â”€ config/
        â”œâ”€â”€ embedding/
        â”œâ”€â”€ vectorstore/
        â”œâ”€â”€ indexing/
        â”œâ”€â”€ reranking/
        â”œâ”€â”€ retrieval/
        â””â”€â”€ dto/

  â–¡ Create pom.xml with dependencies:
    - cartiq-common
    - cartiq-product
    - spring-boot-starter-data-redis
    - google-cloud-aiplatform

â–¡ Implement VertexEmbeddingClient.java:
  â–¡ Initialize PredictionServiceClient
  â–¡ Create embed(String text) method
  â–¡ Use text-embedding-004 model
  â–¡ Return float[] embedding (768 dimensions)

â–¡ Implement CachedEmbeddingService.java:
  â–¡ Inject RedisTemplate<String, byte[]>
  â–¡ Cache keys: emb:product:{id}, emb:query:{hash}
  â–¡ Implement embedProduct(Long productId, String text)
  â–¡ Implement embedQuery(String query)
  â–¡ Add cache invalidation methods
  â–¡ Add metrics (cache hit/miss counters)

â–¡ Add Redis configuration:
  â–¡ Create RedisConfig.java
  â–¡ Configure connection factory
  â–¡ Configure serializers

â–¡ Unit tests:
  â–¡ Test embedding generation
  â–¡ Test cache hit/miss behavior
  â–¡ Test cache invalidation
```

**Deliverables:**
- cartiq-rag module compiles
- Embeddings generated via Vertex AI
- Redis caching working

---

#### Day 4 - RAG Module: Vector Store (11h)

**Goals:**
- Implement Vertex AI Vector Search client
- Implement startup product indexer
- Test semantic search

**Tasks:**
```
â–¡ Implement VectorSearchService.java:
  â–¡ Initialize MatchServiceClient
  â–¡ Configure index endpoint URL
  â–¡ Implement upsertDatapoint(ProductDatapoint)
  â–¡ Implement upsertDatapoints(List<ProductDatapoint>) for batch
  â–¡ Implement removeDatapoint(String id)
  â–¡ Implement search(float[] embedding, int topK, filters)

â–¡ Create supporting classes:
  â–¡ ProductDatapoint.java (id, embedding, category, inStock)
  â–¡ RetrievalFilters.java (categories, priceRange, inStockOnly)
  â–¡ ProductTextBuilder.java (builds text for embedding)

â–¡ Implement StartupProductIndexer.java:
  â–¡ @EventListener(ApplicationReadyEvent.class)
  â–¡ Fetch all products from ProductRepository
  â–¡ Generate embeddings (batch)
  â–¡ Upsert to Vector Search index
  â–¡ Log progress (indexed X/Y products)

â–¡ Test semantic search:
  â–¡ Index sample products
  â–¡ Search for "wireless headphones"
  â–¡ Verify relevant products returned
  â–¡ Test with category filters
```

**Deliverables:**
- Products indexed in Vector Search
- Semantic search returning relevant results
- Startup indexing working

---

#### Day 5 - RAG Module: Incremental Indexing (11h)

**Goals:**
- Implement event-driven indexing for CRUD operations
- Update cartiq-product to publish events
- Test real-time index updates

**Tasks:**
```
â–¡ Create event classes in cartiq-rag:
  â–¡ ProductEvent.java (sealed interface)
  â–¡ ProductCreatedEvent.java (record)
  â–¡ ProductUpdatedEvent.java (record with changedFields)
  â–¡ ProductDeletedEvent.java (record)

â–¡ Update ProductService in cartiq-product:
  â–¡ Inject ApplicationEventPublisher
  â–¡ Publish ProductCreatedEvent in createProduct()
  â–¡ Publish ProductUpdatedEvent in updateProduct()
    - Only if embedding-relevant fields changed
    - Track changedFields (name, description, category)
  â–¡ Publish ProductDeletedEvent in deleteProduct()

â–¡ Implement IncrementalProductIndexer.java:
  â–¡ @EventListener for ProductCreatedEvent
    - Generate embedding
    - Upsert to Vector Search
  â–¡ @EventListener for ProductUpdatedEvent
    - Invalidate embedding cache
    - Generate new embedding
    - Upsert to Vector Search
  â–¡ @EventListener for ProductDeletedEvent
    - Invalidate embedding cache
    - Remove from Vector Search
  â–¡ All listeners @Async("indexingExecutor")

â–¡ Create AsyncConfig.java:
  â–¡ Define indexingExecutor ThreadPoolTaskExecutor
  â–¡ Core pool: 2, Max pool: 5, Queue: 100

â–¡ Test incremental indexing:
  â–¡ Create product â†’ appears in search
  â–¡ Update product name â†’ search reflects change
  â–¡ Delete product â†’ removed from search
```

**Deliverables:**
- Product CRUD triggers index updates
- Cache invalidation working
- Real-time index updates verified

---

#### Day 6 - RAG Module: Retrieval Pipeline (11h)

**Goals:**
- Implement re-ranker for precision
- Implement two-stage ProductRetriever
- Integrate RAG with ChatService

**Tasks:**
```
â–¡ Implement ReRanker interface:
  â–¡ rerank(String query, List<ProductDocument> candidates)
  â–¡ Returns List<RankedProduct> (product + score)

â–¡ Implement VertexReRanker.java:
  â–¡ Initialize RankServiceClient
  â–¡ Build RankRequest with query and candidates
  â–¡ Parse RankResponse and map back to products
  â–¡ Return top-N results

â–¡ Implement QueryBuilder.java:
  â–¡ buildRetrievalQuery(UserContext ctx, String userMessage)
  â–¡ Combine user message + browsing context
  â–¡ Add interested categories
  â–¡ Add recently viewed products (top 3)

â–¡ Implement ProductRetriever.java:
  â–¡ Inject EmbeddingService, VectorSearchService, ReRanker
  â–¡ retrieve(String query, RetrievalFilters filters):
    1. Embed query (check cache)
    2. Vector search â†’ top-50 candidates
    3. Re-rank â†’ top-10 results
    4. Return RankedProduct list
  â–¡ Add metrics (latency, candidate counts)

â–¡ Implement PromptBuilder.java:
  â–¡ buildRagPrompt(UserContext, List<RankedProduct>, userMessage)
  â–¡ Format products with ID, name, category, price, description
  â–¡ Include user context
  â–¡ Add instructions for AI

â–¡ Update ChatService.java:
  â–¡ Inject ProductRetriever, PromptBuilder
  â–¡ In chat():
    1. Get UserContext (placeholder for now)
    2. Build retrieval query
    3. Retrieve relevant products
    4. Build RAG-enhanced prompt
    5. Call Gemini
    6. Return response with product IDs

â–¡ End-to-end test:
  â–¡ Send chat message "recommend a laptop"
  â–¡ Verify products retrieved from Vector Search
  â–¡ Verify re-ranking applied
  â–¡ Verify Gemini response references actual products
```

**Deliverables:**
- Two-stage retrieval (recall + precision) working
- RAG-enhanced chat responses
- Products referenced by actual IDs

---

### Phase 3: Flink Streaming (Days 7-8)

#### Day 7 - Flink Setup + Aggregation (11h)

**Goals:**
- Set up Flink on Confluent Cloud
- Create source tables for Kafka topics
- Implement user behavior aggregation

**Tasks:**
```
â–¡ Confluent Cloud Flink Setup:
  â–¡ Create Flink compute pool (us-central1)
  â–¡ Create Flink SQL workspace
  â–¡ Connect to Kafka cluster

â–¡ Create source tables:
  â–¡ product_views table:
    CREATE TABLE product_views (
      user_id STRING,
      product_id STRING,
      product_name STRING,
      category STRING,
      price DECIMAL(10,2),
      event_time TIMESTAMP(3),
      WATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND
    ) WITH (
      'connector' = 'kafka',
      'topic' = 'product-views',
      'properties.bootstrap.servers' = '...',
      'properties.security.protocol' = 'SASL_SSL',
      'properties.sasl.mechanism' = 'PLAIN',
      'properties.sasl.jaas.config' = '...',
      'format' = 'json'
    );

  â–¡ cart_events table (similar structure)
  â–¡ order_events table (similar structure)

â–¡ Create aggregation query (15-sec windows):
  CREATE TABLE user_profiles WITH (
    'connector' = 'kafka',
    'topic' = 'user-profiles',
    ...
  ) AS
  SELECT
    user_id,
    LISTAGG(product_name) as viewed_products,
    LISTAGG(DISTINCT category) as interested_categories,
    COUNT(*) as view_count,
    MAX(price) as max_price_viewed,
    MIN(price) as min_price_viewed,
    TUMBLE_START(event_time, INTERVAL '15' SECOND) as window_start,
    TUMBLE_END(event_time, INTERVAL '15' SECOND) as window_end
  FROM product_views
  GROUP BY user_id, TUMBLE(event_time, INTERVAL '15' SECOND);

â–¡ Test aggregation:
  â–¡ Send test events via API
  â–¡ Verify user-profiles topic receives aggregated data
  â–¡ Check 15-second window behavior
```

**Deliverables:**
- Flink compute pool running
- User behavior aggregation working
- user-profiles topic populated

---

#### Day 8 - UserContext Cache (11h)

**Goals:**
- Implement in-memory UserContext cache
- Create Kafka consumer for user-profiles
- Integrate context with RAG pipeline

**Tasks:**
```
â–¡ Create UserContext model:
  â–¡ userId, viewedProducts, interestedCategories
  â–¡ viewCount, maxPriceViewed, minPriceViewed
  â–¡ windowStart, windowEnd, lastUpdated

â–¡ Implement UserContextCache.java:
  â–¡ ConcurrentHashMap<String, UserContext>
  â–¡ get(String userId) â†’ UserContext or null
  â–¡ put(String userId, UserContext)
  â–¡ clear()

â–¡ Implement UserProfileConsumer.java:
  â–¡ @KafkaListener(topics = "user-profiles")
  â–¡ Parse JSON message to UserContext
  â–¡ Update cache with latest context
  â–¡ Log updates for debugging

â–¡ Implement cache rebuild on startup:
  â–¡ Configure consumer to read from beginning
  â–¡ On ApplicationReadyEvent:
    - Seek to beginning of user-profiles topic
    - Consume all messages to rebuild cache
    - Log "Cache rebuilt with X user contexts"

â–¡ Integrate with ChatService:
  â–¡ Inject UserContextCache
  â–¡ Get context at start of chat()
  â–¡ Pass to QueryBuilder and PromptBuilder
  â–¡ Include contextUsed in response

â–¡ End-to-end test:
  â–¡ Browse products on API (simulate events)
  â–¡ Wait 15+ seconds for Flink window
  â–¡ Call /api/chat
  â–¡ Verify response mentions browsed products
```

**Deliverables:**
- UserContext cache populated from Kafka
- Cache rebuilds on app restart
- AI responses use real-time context

---

### Phase 4: Frontend (Days 9-12)

#### Day 9 - React Setup + Products (11h)

**Goals:**
- Set up React application
- Implement product listing
- Connect to backend API

**Tasks:**
```
â–¡ Create React app:
  npx create-vite cartiq-frontend --template react-ts
  cd cartiq-frontend

â–¡ Install dependencies:
  npm install @shadcn/ui axios zustand react-router-dom
  npm install -D tailwindcss postcss autoprefixer
  npx tailwindcss init -p
  npx shadcn-ui@latest init

â–¡ Setup project structure:
  src/
  â”œâ”€â”€ components/
  â”‚   â”œâ”€â”€ ui/           (shadcn components)
  â”‚   â”œâ”€â”€ layout/       (Header, Footer)
  â”‚   â””â”€â”€ product/      (ProductCard, ProductGrid)
  â”œâ”€â”€ pages/
  â”‚   â”œâ”€â”€ Home.tsx
  â”‚   â”œâ”€â”€ Products.tsx
  â”‚   â”œâ”€â”€ ProductDetail.tsx
  â”‚   â”œâ”€â”€ Cart.tsx
  â”‚   â””â”€â”€ Checkout.tsx
  â”œâ”€â”€ store/            (zustand stores)
  â”œâ”€â”€ api/              (axios client)
  â””â”€â”€ types/            (TypeScript types)

â–¡ Setup routing (react-router-dom):
  /              â†’ Home
  /products      â†’ Products
  /products/:id  â†’ ProductDetail
  /cart          â†’ Cart
  /checkout      â†’ Checkout

â–¡ Implement API client:
  â–¡ Configure axios base URL
  â–¡ Add auth interceptor (JWT)
  â–¡ Create productApi.ts

â–¡ Implement Products page:
  â–¡ Fetch products from /api/products
  â–¡ ProductCard component
  â–¡ ProductGrid layout
  â–¡ Category filter (sidebar or dropdown)
  â–¡ Search bar

â–¡ Create basic layout:
  â–¡ Header with logo, nav, cart icon
  â–¡ Footer
```

**Deliverables:**
- React app running locally
- Product listing working
- API connection established

---

#### Day 10 - Product Detail + Cart (11h)

**Goals:**
- Implement product detail page
- Implement cart functionality
- Track product views to Kafka

**Tasks:**
```
â–¡ Implement ProductDetail page:
  â–¡ Fetch product by ID
  â–¡ Display product info (image, name, description, price)
  â–¡ Add to cart button
  â–¡ Quantity selector
  â–¡ Related products section (optional)

â–¡ Implement cart store (zustand):
  â–¡ Cart state: items[], total
  â–¡ Actions: addItem, removeItem, updateQuantity, clearCart
  â–¡ Persist to localStorage

â–¡ Implement Cart page:
  â–¡ List cart items
  â–¡ Update quantity controls
  â–¡ Remove item button
  â–¡ Cart total calculation
  â–¡ "Proceed to Checkout" button

â–¡ Track product views:
  â–¡ On ProductDetail mount:
    POST /api/events/product-view
    { userId, productId, productName, category, price }
  â–¡ Add debounce to prevent duplicate events

â–¡ Track cart events:
  â–¡ On addItem:
    POST /api/events/cart-add
    { userId, productId, quantity }
  â–¡ On removeItem:
    POST /api/events/cart-remove
    { userId, productId }
```

**Deliverables:**
- Product detail page working
- Cart add/remove/update working
- Events flowing to Kafka

---

#### Day 11 - Checkout + Auth (11h)

**Goals:**
- Implement checkout flow
- Implement authentication pages
- Integrate JWT auth

**Tasks:**
```
â–¡ Implement Checkout page:
  â–¡ Order summary (items, quantities, total)
  â–¡ Shipping address form (mock for demo)
  â–¡ Payment section (mock "Pay Now" button)
  â–¡ Place order â†’ POST /api/orders
  â–¡ Order confirmation display

â–¡ Track order events:
  â–¡ On order placed:
    POST /api/events/order-placed
    { userId, orderId, items, total }

â–¡ Implement auth store (zustand):
  â–¡ State: user, token, isAuthenticated
  â–¡ Actions: login, logout, register
  â–¡ Persist token to localStorage

â–¡ Implement Login page:
  â–¡ Email/password form
  â–¡ POST /api/auth/login
  â–¡ Store token, redirect to home

â–¡ Implement Register page:
  â–¡ Name, email, password form
  â–¡ POST /api/auth/register
  â–¡ Auto-login after register

â–¡ Add auth interceptor:
  â–¡ Attach Authorization header to requests
  â–¡ Handle 401 â†’ redirect to login

â–¡ Protected routes:
  â–¡ Wrap routes requiring auth
  â–¡ Redirect to login if not authenticated
```

**Deliverables:**
- Checkout flow working
- User authentication working
- Orders created successfully

---

#### Day 12 - AI Chat Widget + Recommendations (11h)

**Goals:**
- Implement AI chat widget
- Implement home page recommendations
- Complete frontend feature set

**Tasks:**
```
â–¡ Implement AI Chat Widget:
  â–¡ Floating chat button (bottom-right corner)
  â–¡ Chat drawer/modal component
  â–¡ Message list (user + AI messages)
  â–¡ Input field + send button
  â–¡ POST /api/chat on send
  â–¡ Display AI responses
  â–¡ Show recommended products as clickable cards
  â–¡ Loading state while AI responds

â–¡ Implement Home page recommendations:
  â–¡ "Recommended For You" section
  â–¡ GET /api/recommendations?userId={userId}
  â–¡ Display personalized product grid
  â–¡ Fallback to "Trending Products" if no context

â–¡ Update Home page:
  â–¡ Hero section with tagline
  â–¡ Recommended For You section
  â–¡ Featured categories
  â–¡ Call-to-action buttons

â–¡ Polish UI:
  â–¡ Loading states for all API calls
  â–¡ Error handling and display
  â–¡ Empty states (empty cart, no results)
  â–¡ Responsive design (mobile-friendly)

â–¡ Test complete flow:
  â–¡ Browse products â†’ events tracked
  â–¡ Wait 15+ seconds
  â–¡ Check home page â†’ recommendations changed!
  â–¡ Open chat â†’ AI knows what you browsed
```

**Deliverables:**
- AI chat widget working
- Home page recommendations personalized
- Complete e-commerce flow

---

### Phase 5: Integration & Polish (Days 13-15)

#### Day 13 - Testing + Cold Start (11h)

**Goals:**
- End-to-end integration testing
- Measure and optimize cold start
- Fix any integration bugs

**Tasks:**
```
â–¡ Cold Start measurement:
  â–¡ New user arrives (no history)
  â–¡ Note: Home page shows trending products
  â–¡ Browse 3-4 products (~20 seconds)
  â–¡ Return to home page after Flink window
  â–¡ Measure time to personalized recommendations
  â–¡ Target: ~15-20 seconds

â–¡ End-to-end flow testing:
  â–¡ Register â†’ Browse â†’ Add to Cart â†’ Checkout
  â–¡ Verify Kafka events at each step
  â–¡ Verify Flink aggregation timing
  â–¡ Verify RAG retrieval quality
  â–¡ Verify AI response relevance

â–¡ Integration bug fixes:
  â–¡ Fix any CORS issues
  â–¡ Fix any auth token issues
  â–¡ Fix any event schema mismatches
  â–¡ Fix any timing issues

â–¡ RAG quality testing:
  â–¡ Test various queries
  â–¡ Verify retrieved products are relevant
  â–¡ Verify re-ranking improves results
  â–¡ Adjust similarity thresholds if needed

â–¡ Performance testing:
  â–¡ Measure API response times
  â–¡ Measure chat response times
  â–¡ Identify any bottlenecks
```

**Deliverables:**
- Cold start documented (~15 sec)
- All integrations verified
- Major bugs fixed

---

#### Day 14 - Data Seeder (11h)

**Goals:**
- Create demo data seeder
- Prepare realistic product catalog
- Create event simulator for demo

**Tasks:**
```
â–¡ Implement DataSeederService.java:
  â–¡ Fetch products from DummyJSON API or custom JSON
  â–¡ Categories: Electronics, Clothing, Home, Sports, etc.
  â–¡ ~100-200 products for demo
  â–¡ Create 5-10 test users
  â–¡ Run on startup (dev profile only)

â–¡ Product data requirements:
  â–¡ Realistic names and descriptions
  â–¡ Appropriate price ranges
  â–¡ Good category distribution
  â–¡ Product images (URLs or placeholders)

â–¡ Implement EventSimulator.java (optional):
  â–¡ Admin endpoint: POST /api/admin/simulate/start
  â–¡ Simulates user browsing patterns
  â–¡ Generates realistic event sequences
  â–¡ Useful for demo if no live users

â–¡ Seed data for demo scenarios:
  â–¡ User "alice" interested in Electronics
  â–¡ User "bob" interested in Sports
  â–¡ User "carol" interested in Home & Kitchen
  â–¡ Pre-populate some browsing history

â–¡ Test with seeded data:
  â–¡ Verify products indexed in Vector Search
  â–¡ Verify semantic search works
  â–¡ Verify recommendations quality
```

**Deliverables:**
- Demo database seeded
- Realistic product catalog
- Demo scenarios prepared

---

#### Day 15 - Deployment (11h)

**Goals:**
- Deploy backend to Cloud Run
- Deploy frontend to Firebase Hosting
- Verify production environment

**Tasks:**
```
â–¡ Backend deployment:
  â–¡ Build JAR: mvn clean package -DskipTests
  â–¡ Create Dockerfile (if not exists)
  â–¡ Build Docker image
  â–¡ Push to Google Container Registry
  â–¡ Deploy to Cloud Run:
    gcloud run deploy cartiq-backend \
      --image gcr.io/PROJECT_ID/cartiq-backend \
      --platform managed \
      --region us-central1 \
      --allow-unauthenticated \
      --set-env-vars "..."

â–¡ Configure Cloud Run environment:
  â–¡ CONFLUENT_BOOTSTRAP_SERVERS
  â–¡ CONFLUENT_API_KEY / SECRET
  â–¡ GCP_PROJECT_ID
  â–¡ REDIS_HOST / PORT
  â–¡ VECTOR_SEARCH_INDEX_ENDPOINT
  â–¡ Database connection (Cloud SQL or H2)

â–¡ Frontend deployment:
  â–¡ Update API base URL to Cloud Run URL
  â–¡ Build: npm run build
  â–¡ Firebase init: firebase init hosting
  â–¡ Deploy: firebase deploy

â–¡ Post-deployment verification:
  â–¡ Test all API endpoints
  â–¡ Test frontend flows
  â–¡ Verify Kafka connectivity
  â–¡ Verify Vector Search connectivity
  â–¡ Verify Redis connectivity
  â–¡ Test AI chat responses

â–¡ CORS configuration:
  â–¡ Allow Firebase hosting domain
  â–¡ Test cross-origin requests
```

**Deliverables:**
- Backend live on Cloud Run
- Frontend live on Firebase
- All services connected

---

### Phase 6: Demo & Submit (Days 16-19)

#### Day 16 - Production Testing (11h)

**Goals:**
- Comprehensive production testing
- Fix any production-specific bugs
- Prepare demo environment

**Tasks:**
```
â–¡ Production smoke testing:
  â–¡ Test on multiple browsers (Chrome, Firefox, Safari)
  â–¡ Test on mobile devices
  â–¡ Test all user flows end-to-end
  â–¡ Verify no console errors

â–¡ Production bug fixes:
  â–¡ Fix any production-only issues
  â–¡ Handle edge cases
  â–¡ Improve error messages

â–¡ Performance verification:
  â–¡ Check Cloud Run logs for errors
  â–¡ Monitor response times
  â–¡ Check Redis cache hit rates
  â–¡ Verify Flink processing

â–¡ Demo preparation:
  â–¡ Create demo user account
  â–¡ Clear/reset demo data if needed
  â–¡ Prepare demo script walkthrough
  â–¡ Test demo flow multiple times
```

**Deliverables:**
- Production fully tested
- Demo environment ready
- No critical bugs

---

#### Day 17 - Demo Video Recording (11h)

**Goals:**
- Write demo script
- Record demo video
- Capture all key features

**Tasks:**
```
â–¡ Write demo script (3 minutes):

  0:00-0:15 - Intro
  "Hi, I'm [name] and this is CartIQ - an AI shopping assistant
   that personalizes recommendations in just 15 seconds."

  0:15-0:30 - Show empty state
  "When a new user visits, they see trending products.
   No personalization yet."

  0:30-1:00 - Browse products
  "Watch as I browse some electronics...
   [Click through 3-4 products]
   Each view is streamed to Kafka in real-time."

  1:00-1:30 - Show personalization (WOW moment!)
  "Now I return to the home page... and look!
   The recommendations changed - all electronics!
   This happened in just 15 seconds with NO account needed."

  1:30-2:00 - AI Chat
  "Let me ask the AI for recommendations...
   [Type: 'recommend a laptop for programming']
   Notice it references products from our actual catalog,
   not generic suggestions. That's RAG in action."

  2:00-2:30 - Architecture explanation
  [Show architecture diagram]
  "Here's how it works:
   - Kafka streams user events
   - Flink aggregates behavior in 15-sec windows
   - RAG retrieves relevant products from Vector Search
   - Gemini generates personalized responses"

  2:30-3:00 - Wrap up
  "CartIQ solves the cold start problem for small businesses.
   Personalization that used to take weeks now takes seconds.
   Thank you!"

â–¡ Recording setup:
  â–¡ Clean browser (incognito mode)
  â–¡ Hide bookmarks bar
  â–¡ 1080p screen recording
  â–¡ Clear, quiet audio
  â–¡ Good lighting if showing face

â–¡ Record demo:
  â–¡ Practice 2-3 times first
  â–¡ Record full demo
  â–¡ Capture screen + audio
  â–¡ Record backup take
```

**Deliverables:**
- Demo script finalized
- Raw video recorded
- Backup recording saved

---

#### Day 18 - Demo Video Editing (11h)

**Goals:**
- Edit demo video
- Add polish (captions, overlays)
- Upload to YouTube

**Tasks:**
```
â–¡ Video editing:
  â–¡ Trim dead time and mistakes
  â–¡ Adjust audio levels
  â–¡ Add intro/outro slides
  â–¡ Add architecture diagram overlay
  â–¡ Add captions/subtitles
  â–¡ Add transitions between sections
  â–¡ Optional: background music (subtle)

â–¡ Export settings:
  â–¡ Resolution: 1080p minimum
  â–¡ Format: MP4 (H.264)
  â–¡ Frame rate: 30fps

â–¡ Upload to YouTube:
  â–¡ Title: "CartIQ - AI Shopping Assistant | Confluent Hackathon"
  â–¡ Description with:
    - Brief project summary
    - Technologies used
    - Team members
    - Links to GitHub and live demo
  â–¡ Tags: AI, Kafka, Flink, Gemini, RAG, e-commerce
  â–¡ Visibility: Public or Unlisted
  â–¡ Thumbnail: Custom with CartIQ branding

â–¡ Final review:
  â–¡ Watch full video
  â–¡ Check audio sync
  â–¡ Verify all sections clear
  â–¡ Get feedback if possible
```

**Deliverables:**
- Polished demo video
- Uploaded to YouTube
- Shareable link ready

---

#### Day 19 - Final Submission (11h)

**Goals:**
- Final production verification
- Complete Devpost submission
- Submit before deadline!

**Tasks:**
```
â–¡ Final verification:
  â–¡ Test live URLs one more time
  â–¡ Verify video is accessible
  â–¡ Test on friend's device if possible

â–¡ Documentation:
  â–¡ Update README.md with:
    - Project description
    - Architecture overview
    - Setup instructions
    - Environment variables
    - API documentation
  â–¡ Ensure LICENSE file exists (MIT)
  â–¡ Add architecture diagram to repo

â–¡ Devpost submission:
  â–¡ Project title: "CartIQ - AI Shopping Assistant"
  â–¡ Tagline: "Personalized recommendations in ~15 seconds"

  â–¡ Description:
    ## What it does
    CartIQ is an AI-powered shopping assistant that delivers
    personalized product recommendations in just 15 seconds -
    solving the e-commerce cold start problem.

    ## How we built it
    - **Kafka** streams user events in real-time
    - **Flink** aggregates behavior in 15-second windows
    - **RAG** retrieves products from Vertex AI Vector Search
    - **Gemini** generates personalized recommendations
    - **React** frontend with AI chat widget

    ## Key Features
    - Cold start personalization (~15 seconds)
    - Two recommendation surfaces (home page + AI chat)
    - Production-grade RAG with re-ranking
    - Real-time streaming architecture

  â–¡ Links:
    âœ“ Live demo: https://cartiq-xxx.web.app
    âœ“ GitHub: https://github.com/xxx/cartiq-backend
    âœ“ Demo video: https://youtube.com/watch?v=xxx

  â–¡ Screenshots (5):
    1. Home page with personalized recommendations
    2. AI chat widget conversation
    3. Product browsing page
    4. Architecture diagram
    5. Confluent Cloud dashboard (optional)

  â–¡ Built with:
    Apache Kafka, Apache Flink, Google Cloud Vertex AI,
    Gemini, React, Spring Boot, Redis

  â–¡ Select challenge: Confluent Challenge

â–¡ Final checklist:
  âœ“ Hosted URL works
  âœ“ Video is accessible (not private)
  âœ“ GitHub repo is public
  âœ“ All Devpost fields filled
  âœ“ Submitted before 2:00 PM PT deadline

â–¡ SUBMIT! ğŸ‰
```

**Deliverables:**
- Complete Devpost submission
- All links verified working
- Submitted before deadline!

---

## Updated Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CARTIQ ARCHITECTURE (with RAG)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                                   â”‚
â”‚  â”‚ Frontend â”‚ (React + Firebase Hosting)                                        â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                                                   â”‚
â”‚       â”‚                                                                         â”‚
â”‚       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚       â”‚ (events)                   â”‚ (page load)          â”‚ (chat)              â”‚
â”‚       â–¼                            â–¼                      â–¼                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Kafka   â”‚              â”‚ GET /api/       â”‚    â”‚ POST /api/chat  â”‚            â”‚
â”‚  â”‚ Topics  â”‚              â”‚ recommendations â”‚    â”‚                 â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚       â”‚                            â”‚                      â”‚                     â”‚
â”‚       â–¼                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚                                 â”‚
â”‚  â”‚ Flink   â”‚ (15-sec windows)                 â–¼                                 â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚       â”‚                             â”‚ UserContext Cache â”‚                       â”‚
â”‚       â”‚ write profiles              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚       â–¼                                       â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        consume                   â”‚                                 â”‚
â”‚  â”‚ user-   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                 â”‚
â”‚  â”‚ profilesâ”‚                                  â–¼                                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚                                  â”‚              AI MODULE                   â”‚    â”‚
â”‚                                  â”‚                                          â”‚    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  UserContext + Query                     â”‚    â”‚
â”‚  â”‚      RAG PIPELINE           â”‚ â”‚         â”‚                                â”‚    â”‚
â”‚  â”‚                             â”‚ â”‚         â–¼                                â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚  â”‚ Product â”‚â”€â–¶â”‚ Startup  â”‚  â”‚ â”‚  â”‚   Query     â”‚â”€â”€â”€â–¶â”‚ Embedding Cacheâ”‚   â”‚    â”‚
â”‚  â”‚  â”‚   DB    â”‚  â”‚ Indexer  â”‚  â”‚ â”‚  â”‚  Builder    â”‚    â”‚    (Redis)     â”‚   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â”‚       â”‚            â”‚        â”‚ â”‚         â”‚                   â”‚            â”‚    â”‚
â”‚  â”‚       â”‚ CRUD       â”‚embed   â”‚ â”‚         â”‚ embed      miss   â”‚            â”‚    â”‚
â”‚  â”‚       â–¼            â–¼        â”‚ â”‚         â–¼                   â–¼            â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚  â”‚Incrementalâ”‚ â”‚ Vertex AIâ”‚  â”‚ â”‚  â”‚    Vertex AI Vector Search     â”‚     â”‚    â”‚
â”‚  â”‚  â”‚ Indexer  â”‚â”€â–¶â”‚ Vector   â”‚â—€â”€â”¼â”€â”¼â”€â”€â”‚      (semantic search)         â”‚     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ Search   â”‚  â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚                 â”‚ top-50                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                 â–¼                        â”‚    â”‚
â”‚                                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚                                  â”‚  â”‚    Cross-Encoder Re-Ranker      â”‚     â”‚    â”‚
â”‚                                  â”‚  â”‚    (Vertex AI Ranking API)      â”‚     â”‚    â”‚
â”‚                                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚                                  â”‚                 â”‚ top-10                 â”‚    â”‚
â”‚                                  â”‚                 â–¼                        â”‚    â”‚
â”‚                                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚                                  â”‚  â”‚       Prompt Builder            â”‚     â”‚    â”‚
â”‚                                  â”‚  â”‚  (context + products + query)   â”‚     â”‚    â”‚
â”‚                                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚                                  â”‚                 â”‚                        â”‚    â”‚
â”‚                                  â”‚                 â–¼                        â”‚    â”‚
â”‚                                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚                                  â”‚  â”‚         Gemini 2.5 Flash        â”‚     â”‚    â”‚
â”‚                                  â”‚  â”‚    (personalized response)      â”‚     â”‚    â”‚
â”‚                                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Technology Stack

| Layer | Technology | Deployment |
|-------|------------|------------|
| Frontend | React + TypeScript + shadcn/ui | Firebase Hosting |
| Backend | Spring Boot 3.2 (Modular Monolith) | Google Cloud Run |
| Database | H2 (demo) / Cloud SQL (prod) | GCP |
| Streaming | Apache Kafka | Confluent Cloud |
| Processing | Apache Flink | Confluent Cloud |
| Vector Store | Vertex AI Vector Search | GCP |
| Embedding Cache | Cloud Memorystore (Redis) | GCP |
| AI/ML | Gemini 2.5 Flash + RAG | Vertex AI |

---

## Risk Mitigation

| Risk | Likelihood | Mitigation |
|------|------------|------------|
| Vector Search setup issues | Medium | Day 1 dedicated; fallback to in-memory |
| Re-ranker API issues | Low | Can disable re-ranking (config flag) |
| Flink setup complex | Medium | Start Day 7; fallback: direct Kafka â†’ cache |
| Frontend delays | Medium | Use shadcn/ui heavily; cut animations |
| Integration bugs | Medium | Days 13-15 buffer for fixes |
| Demo failure | Low | Pre-record backup video Day 17 |

---

## Success Criteria

### Must Achieve
1. âœ… Events flowing: Spring Boot â†’ Kafka (working)
2. [ ] Flink aggregation â†’ user-profiles topic
3. [ ] RAG pipeline: Vector Search â†’ Re-rank â†’ Gemini
4. [ ] Two recommendation surfaces: Home page + AI chat
5. [ ] Cold Start: Personalized in ~15 seconds
6. [ ] Live demo URL working
7. [ ] Complete Devpost submission

### Differentiators
- **Production-grade RAG** with Vector Search + Re-ranking
- **Embedding cache** for low latency
- **Real-time indexing** on product changes
- **Cold Start Killer** - personalized in ~15 seconds
- **SMB impact narrative** - democratizing personalization

---

## Go/No-Go Checkpoints

| Day | Checkpoint | Go Criteria | Fallback |
|-----|------------|-------------|----------|
| 1 | GCP Infrastructure | Vector Search deployed | Use in-memory store |
| 6 | RAG Pipeline | End-to-end retrieval working | Simplify to basic search |
| 8 | Flink + Context | User context in AI responses | Direct Kafka â†’ cache |
| 12 | Frontend | Core flows working | Simplify UI |
| 15 | Deployment | Production URLs live | Debug and fix |

---

## Daily Checklist Template

```
Date: ___________
Day: ___ of 19

Goals for today:
â–¡ _________________
â–¡ _________________
â–¡ _________________

Completed:
âœ“ _________________
âœ“ _________________

Blockers:
- _________________

Tomorrow:
â–¡ _________________
â–¡ _________________
```

---

*Last updated: December 12, 2025*
